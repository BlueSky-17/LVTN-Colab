{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPGBhgzIkIq1Wvh4LQFVGJn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install underthesea"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSCRmRaFIWKH","executionInfo":{"status":"ok","timestamp":1716307832410,"user_tz":-420,"elapsed":28940,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}},"outputId":"2a875a66-42b2-4e98-f26b-6482cc6562ed"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting underthesea\n","  Downloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n","Collecting python-crfsuite>=0.9.6 (from underthesea)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n","Collecting underthesea-core==1.0.4 (from underthesea)\n","  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2023.12.25)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n","Installing collected packages: underthesea-core, python-crfsuite, underthesea\n","Successfully installed python-crfsuite-0.9.10 underthesea-6.8.0 underthesea-core-1.0.4\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2kur6ZRd7HVT","executionInfo":{"status":"ok","timestamp":1716307875129,"user_tz":-420,"elapsed":42725,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from underthesea import  word_tokenize\n","\n","from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn import decomposition, ensemble\n","\n","import pandas, xgboost, numpy, textblob, string\n","\n","from keras.preprocessing import text, sequence\n","from keras import layers, models, optimizers\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from gensim.utils import simple_preprocess\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModel, logging\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","logging.set_verbosity_error()\n","\n"]},{"cell_type":"code","source":["drive.mount('/drive')\n","path = '/drive/MyDrive/Colab Notebooks/Data/Data_train_1.xlsx'\n","\n","df = pd.read_excel(path)\n","\n","print(df);\n","\n","rows = len(df)\n","print(rows)\n","\n"],"metadata":{"id":"bJPBJpht3ZAM","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1716307896633,"user_tz":-420,"elapsed":21508,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}},"outputId":"02c7ee2c-b368-47e4-8228-2c6652197975"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/drive/MyDrive/Colab Notebooks/Data/Data_train_1.xlsx'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-da10f141dcb8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/drive/MyDrive/Colab Notebooks/Data/Data_train_1.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1497\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     ) as handle:\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/drive/MyDrive/Colab Notebooks/Data/Data_train_1.xlsx'"]}]},{"cell_type":"code","source":["# for i in range(rows):\n","#   df['WORDS'][i] = word_tokenize(df['WORDS'][i], format = 'text')\n","\n","print(df)"],"metadata":{"id":"wQle3tGlJvl_","executionInfo":{"status":"aborted","timestamp":1716307896634,"user_tz":-420,"elapsed":5,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","#split train set and validation test from df\n","\n","\n","# print(train_x.info())\n","# print(valid_x.info())\n"],"metadata":{"id":"OMHz11hQ9Ob0","executionInfo":{"status":"aborted","timestamp":1716307896634,"user_tz":-420,"elapsed":5,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n","      # fit the training dataset on the classifier\n","      classifier.fit(feature_vector_train, label)\n","\n","      # predict the labels on validation dataset\n","      predictions = classifier.predict(feature_vector_valid)\n","\n","      if is_neural_net:\n","          predictions = predictions.argmax(axis=-1)\n","\n","      return metrics.accuracy_score(predictions, valid_y)\n","\n","\n","result = open(\"result.txt\",\"w\")\n","loop = 100\n","average_acc_NB = 0\n","average_acc_SVM = 0\n","average_acc_RF = 0\n","\n","for i in range(loop):\n","  print(\"-\"*30)\n","  print(f\"Loop {i+1}:\")\n","  result.write(f\"\\nLoop {i+1}:\\n\\n\")\n","  train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['WORDS'], df['Label'])\n","\n","  # Feature extraction using ngram level TF-IDF\n","  tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n","  tfidf_vect_ngram.fit(df['WORDS'])\n","  xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n","  xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n","\n","  #Naive Bayes\n","  accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n","  average_acc_NB += accuracy\n","  print(\"NB, N-Gram Vectors: \", accuracy)\n","  result.write(f\"NB, N-Gram Vectors: {accuracy}\\n\\n\")\n","\n","  #SVM\n","  accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n","  average_acc_SVM += accuracy\n","  print(\"SVM, N-Gram Vectors: \", accuracy)\n","  result.write(f\"SVM, N-Gram Vectors: {accuracy}\\n\\n\")\n","\n","  #Random Forest\n","  accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n","  average_acc_RF += accuracy\n","  print(\"RF, N-Gram Vectors: \", accuracy)\n","  result.write(f\"RF, N-Gram Vectors: {accuracy}\\n\\n\")\n","\n","print(f\"Average accuracy of NB: {average_acc_NB/loop}\")\n","print(f\"Average accuracy of SVM: {average_acc_SVM/loop}\")\n","print(f\"Average accuracy of RF: {average_acc_RF/loop}\")"],"metadata":{"id":"Wf8cdIP-adgK","executionInfo":{"status":"aborted","timestamp":1716307896634,"user_tz":-420,"elapsed":5,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df)"],"metadata":{"id":"mxBi-xKSkJRS","executionInfo":{"status":"aborted","timestamp":1716307896634,"user_tz":-420,"elapsed":5,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#using PhoBert\n","def seed_everything(seed_value):\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = True\n","\n","seed_everything(86)"],"metadata":{"id":"JZLBOt1bceQI","executionInfo":{"status":"aborted","timestamp":1716307896635,"user_tz":-420,"elapsed":6,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","EPOCHS = 6\n","N_SPLITS = 5\n","\n","skf = StratifiedKFold(n_splits=N_SPLITS)\n","for fold, (_, val_) in enumerate(skf.split(X=df, y=df.Label)):\n","    df.loc[val_, \"kfold\"] = fold"],"metadata":{"id":"4aq82jrwieOo","executionInfo":{"status":"aborted","timestamp":1716307896635,"user_tz":-420,"elapsed":5,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n","\n","class TypeClassificationDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len=120):\n","        self.df = df\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        To customize dataset, inherit from Dataset class and implement\n","        __len__ & __getitem__\n","        __getitem__ should return\n","            data:\n","                input_ids\n","                attention_masks\n","                text\n","                targets\n","        \"\"\"\n","        row = self.df.iloc[index]\n","        text, label = self.get_input_data(row)\n","\n","        # Encode_plus will:\n","        # (1) split text into token\n","        # (2) Add the '[CLS]' and '[SEP]' token to the start and end\n","        # (3) Truncate/Pad sentence to max length\n","        # (4) Map token to their IDS\n","        # (5) Create attention mask\n","        # (6) Return a dictionary of outputs\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_token_type_ids=False,\n","            return_tensors='pt',\n","        )\n","\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_masks': encoding['attention_mask'].flatten(),\n","            'targets': torch.tensor(label, dtype=torch.long),\n","        }\n","\n","    def get_input_data(self, row):\n","        # Preprocessing: {remove icon, special character, lower}\n","        text = row['WORDS']\n","        text = ' '.join(simple_preprocess(text))\n","        label = row['Label']\n","\n","        return text, label"],"metadata":{"id":"8q2u6s8Wi27k","executionInfo":{"status":"aborted","timestamp":1716307896635,"user_tz":-420,"elapsed":5,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TypeClassifier(nn.Module):\n","    def __init__(self, n_classes):\n","        super(TypeClassifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","        self.drop = nn.Dropout(p=0.3)\n","        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n","        nn.init.normal_(self.fc.weight, std=0.02)\n","        nn.init.normal_(self.fc.bias, 0)\n","\n","    def forward(self, input_ids, attention_mask):\n","        last_hidden_state, output = self.bert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            return_dict=False # Dropout will errors if without this\n","        )\n","\n","        x = self.drop(output)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"5rUhvv52jSHO","executionInfo":{"status":"aborted","timestamp":1716307896636,"user_tz":-420,"elapsed":6,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, criterion, optimizer, train_loader):\n","    model.train()\n","    losses = []\n","    correct = 0\n","\n","    for data in train_loader:\n","        input_ids = data['input_ids'].to(device)\n","        attention_mask = data['attention_masks'].to(device)\n","        targets = data['targets'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","        )\n","\n","        loss = criterion(outputs, targets)\n","        _, pred = torch.max(outputs, dim=1)\n","\n","        correct += torch.sum(pred == targets)\n","        losses.append(loss.item())\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        lr_scheduler.step()\n","\n","    print(f'Train Accuracy: {correct.double()/len(train_loader.dataset)} Loss: {np.mean(losses)}')\n","\n","def eval(test_data = False):\n","    model.eval()\n","    losses = []\n","    correct = 0\n","\n","    with torch.no_grad():\n","        data_loader = test_loader if test_data else valid_loader\n","        for data in data_loader:\n","            input_ids = data['input_ids'].to(device)\n","            attention_mask = data['attention_masks'].to(device)\n","            targets = data['targets'].to(device)\n","\n","            outputs = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask\n","            )\n","\n","            _, pred = torch.max(outputs, dim=1)\n","\n","            loss = criterion(outputs, targets)\n","            correct += torch.sum(pred == targets)\n","            losses.append(loss.item())\n","\n","    if test_data:\n","        print(f'Test Accuracy: {correct.double()/len(test_loader.dataset)} Loss: {np.mean(losses)}')\n","        return correct.double()/len(test_loader.dataset)\n","    else:\n","        print(f'Valid Accuracy: {correct.double()/len(valid_loader.dataset)} Loss: {np.mean(losses)}')\n","        return correct.double()/len(valid_loader.dataset)"],"metadata":{"id":"jI10eN9FjvAn","executionInfo":{"status":"aborted","timestamp":1716307896636,"user_tz":-420,"elapsed":6,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_loaders(df, fold):\n","\n","    df_train = df[df.kfold != fold].reset_index(drop=True)\n","    df_valid = df[df.kfold == fold].reset_index(drop=True)\n","\n","    train_dataset = TypeClassificationDataset(df_train, tokenizer, max_len=120)\n","    valid_dataset = TypeClassificationDataset(df_valid, tokenizer, max_len=120)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n","    valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=True, num_workers=2)\n","\n","    return train_loader, valid_loader"],"metadata":{"id":"66yEU8vbj5uV","executionInfo":{"status":"aborted","timestamp":1716307896636,"user_tz":-420,"elapsed":6,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for fold in range(skf.n_splits):\n","#     print(f'\\n-----------Fold: {fold+1} ------------------')\n","#     train_loader, valid_loader = prepare_loaders(df, fold=fold)\n","#     model = TypeClassifier(n_classes=7).to(device)\n","#     criterion = nn.CrossEntropyLoss()\n","#     # Recommendation by BERT: lr: 5e-5, 2e-5, 3e-5\n","#     # Batchsize: 16, 32\n","#     optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","#     lr_scheduler = get_linear_schedule_with_warmup(\n","#                 optimizer,\n","#                 num_warmup_steps=0,\n","#                 num_training_steps=len(train_loader)*EPOCHS\n","#             )\n","#     best_acc = 0\n","#     for epoch in range(EPOCHS):\n","#         print(f'Epoch {epoch+1}/{EPOCHS}')\n","#         print('-'*30)\n","\n","#         train(model, criterion, optimizer, train_loader)\n","#         val_acc = eval()\n","\n","#         if val_acc > best_acc:\n","#             torch.save(model.state_dict(), f'/drive/MyDrive/Colab Notebooks/Data/phobert_fold{fold+1}.pth')\n","#             best_acc = val_acc"],"metadata":{"id":"5ebaA26gkwV_","executionInfo":{"status":"aborted","timestamp":1716307896636,"user_tz":-420,"elapsed":6,"user":{"displayName":"QUÂN THI KHẮC","userId":"05822997031274677504"}}},"execution_count":null,"outputs":[]}]}